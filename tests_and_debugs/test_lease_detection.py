#!/usr/bin/env python3
"""
Test Lease Detection on Real Page
Test the extract_lease_terms_from_page method against the real page
"""

import sys
import os
import asyncio
import logging

# Add parent directory to path so we can import modules from the root
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from encar_scraper_api import EncarScraperAPI
import yaml

async def test_lease_detection():
    """Test lease detection on the real page"""
    print("ğŸ§ª Testing Lease Detection on Real Page")
    print("=" * 50)
    
    # Load config
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # Create scraper instance
    scraper = EncarScraperAPI(config)
    
    # Test URL
    test_url = "https://fem.encar.com/cars/detail/39727392"
    
    print(f"ğŸ”— Testing URL: {test_url}")
    
    try:
        async with scraper:
            # Launch browser in non-headless mode for debugging
            from playwright.async_api import async_playwright
            
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=False)  # Non-headless for debugging
                page = await browser.new_page()
                
                print("ğŸŒ Navigating to page...")
                
                # Navigate with better loading strategy
                await page.goto(test_url, wait_until='networkidle', timeout=60000)
                
                # Wait for the page to be fully loaded
                print("â³ Waiting for page to fully load...")
                await page.wait_for_timeout(10000)  # Wait 10 seconds for any dynamic content
                
                # Wait for any specific elements that might indicate the page is ready
                try:
                    # Wait for the main content to be visible
                    await page.wait_for_selector('.DetailCarPhotoPc_info__0IA0t', timeout=10000)
                    print("âœ… Main content loaded")
                except:
                    print("âš ï¸ Main content selector not found, continuing anyway...")
                
                # Check page title and content
                page_title = await page.title()
                print(f"ğŸ“„ Page title: {page_title}")
                
                # Get page content after ensuring it's fully loaded
                page_content = await page.content()
                print(f"ğŸ“„ Page content length: {len(page_content)} characters")
                
                # Check for lease keywords in content
                lease_keywords = ["ë¦¬ìŠ¤", "ë ŒíŠ¸", "ì›” ë‚©ì…ê¸ˆ", "ë³´ì¦ê¸ˆ", "ë¦¬ìŠ¤ë£Œ", "ì›”ë¦¬ìŠ¤", "ë¦¬ìŠ¤ê¸°ê°„", "ì›” ë ŒíŠ¸ë¹„", "ë ŒíŠ¸ë£Œ"]
                print("\nğŸ” Checking for lease keywords:")
                for keyword in lease_keywords:
                    if keyword in page_content:
                        print(f"   âœ… Found: {keyword}")
                    else:
                        print(f"   âŒ Not found: {keyword}")
                
                # Test the extract_lease_terms_from_page method
                print("\nğŸ§ª Testing extract_lease_terms_from_page method...")
                lease_info = await scraper.extract_lease_terms_from_page(page)
                
                if lease_info:
                    print("âœ… Lease terms extracted successfully!")
                    print(f"   Is Lease: {lease_info.get('is_lease', False)}")
                    print(f"   Deposit: {lease_info.get('deposit')}ë§Œì›")
                    print(f"   Monthly Payment: {lease_info.get('monthly_payment')}ë§Œì›")
                    print(f"   Lease Term: {lease_info.get('lease_term_months')} months")
                    print(f"   True Price: {lease_info.get('true_price')}ë§Œì›")
                    print(f"   Total Cost: {lease_info.get('total_cost')}ë§Œì›")
                else:
                    print("âŒ No lease terms extracted")
                
                # Let's also check the page content more specifically
                print("\nğŸ” Detailed content analysis:")
                
                # Look for specific lease-related text
                lease_indicators = [
                    "ì¸ìˆ˜ê¸ˆ",
                    "ì°¨ëŸ‰ê°€ê²©", 
                    "ì›”ë¦¬ìŠ¤ë£Œ",
                    "ê°œì›”",
                    "ë¦¬ìŠ¤",
                    "ë ŒíŠ¸"
                ]
                
                for indicator in lease_indicators:
                    if indicator in page_content:
                        print(f"   âœ… Found: {indicator}")
                        # Find the context around this indicator
                        index = page_content.find(indicator)
                        if index != -1:
                            context_start = max(0, index - 100)
                            context_end = min(len(page_content), index + 100)
                            context = page_content[context_start:context_end]
                            print(f"      Context: {context}")
                    else:
                        print(f"   âŒ Not found: {indicator}")
                
                # Try to find any lease-related elements on the page
                print("\nğŸ” Looking for lease-related elements on the page...")
                
                # Look for any elements that might contain lease information
                lease_selectors = [
                    '[class*="lease"]',
                    '[class*="rent"]',
                    '[class*="ë¦¬ìŠ¤"]',
                    '[class*="ë ŒíŠ¸"]',
                    '[class*="DetailLease"]',
                    '[class*="DetailRent"]'
                ]
                
                for selector in lease_selectors:
                    try:
                        elements = await page.query_selector_all(selector)
                        if elements:
                            print(f"   âœ… Found {len(elements)} elements with selector: {selector}")
                            for i, elem in enumerate(elements[:3]):  # Show first 3
                                try:
                                    text = await elem.inner_text()
                                    print(f"      Element {i+1}: {text[:100]}...")
                                except:
                                    print(f"      Element {i+1}: [Could not get text]")
                    except Exception as e:
                        print(f"   âŒ Error with selector {selector}: {e}")
                
                # Look for any buttons or links that might reveal lease information
                print("\nğŸ” Looking for buttons that might reveal lease info...")
                try:
                    buttons = await page.query_selector_all('button')
                    for button in buttons[:10]:  # Check first 10 buttons
                        try:
                            button_text = await button.inner_text()
                            if any(keyword in button_text for keyword in ["ë¦¬ìŠ¤", "ë ŒíŠ¸", "ìƒì„¸", "ìì„¸íˆ"]):
                                print(f"   âœ… Found relevant button: {button_text}")
                        except:
                            continue
                except Exception as e:
                    print(f"   âŒ Error checking buttons: {e}")
                
                # Wait a bit so we can see the browser
                print("\nâ³ Waiting 15 seconds to inspect the page...")
                await page.wait_for_timeout(15000)
                
                await browser.close()
                
    except Exception as e:
        print(f"âŒ Error during testing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_lease_detection()) 